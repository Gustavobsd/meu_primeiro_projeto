{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gustavobsd/meu_primeiro_projeto/blob/master/projeto%20de%20IA\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "MEMBROS: Davi Rosa de Jesus\n",
        "         Erick de Oliveira Soares\n",
        "         Gabriel Silva Costa\n",
        "         Gustavo Bruno Sales David\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ksYJvr3R3kN5",
        "outputId": "3460a17e-2e37-4e09-81ea-76ac85f8628e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nMEMBROS: Davi Rosa de Jesus\\n         Erick de Oliveira Soares\\n         Gabriel Silva Costa\\n         Gustavo Bruno Sales David\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "r_vMSKP1F806",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa049d3f-cfc2-4ec8-9bcd-61059953ae7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q PyMuPDF==1.24.10 PyPDF2 requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "tVh1saMYFlWq",
        "outputId": "0079e1c4-d99d-4f1d-e847-821fbf7bfd94"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-26cc08b5-c683-4598-8aaf-a4fb467347a7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-26cc08b5-c683-4598-8aaf-a4fb467347a7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Projeto%201.pdf (1).pdf to Projeto%201.pdf (1).pdf\n",
            "âœ… PDF enviado com sucesso.\n",
            "ğŸ“‚ Caminho completo: /content/Projeto%201.pdf (1).pdf\n"
          ]
        }
      ],
      "source": [
        "# ===============================================================\n",
        "# ğŸ“˜ ASSISTENTE DE CARDÃPIO - IA PDF (PIZZARIA)\n",
        "# ===============================================================\n",
        "\n",
        "# --- Upload do PDF ---\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()  # Selecione seu arquivo .pdf (cardÃ¡pio)\n",
        "if not uploaded:\n",
        "    raise RuntimeError(\"Nenhum arquivo foi enviado. Execute novamente e selecione o PDF.\")\n",
        "\n",
        "pdf_filename = list(uploaded.keys())[0]\n",
        "PDF_PATH = os.path.join(\"/content\", pdf_filename)\n",
        "\n",
        "print(\"âœ… PDF enviado com sucesso.\")\n",
        "print(\"ğŸ“‚ Caminho completo:\", PDF_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GmzO-8BYJchE"
      },
      "outputs": [],
      "source": [
        "# 2 ConfiguraÃ§Ãµes\n",
        "\n",
        "OPENROUTER_API_KEY = \"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\"\n",
        "\n",
        "MODEL_NAME = \"mistralai/mistral-7b-instruct\"\n",
        "\n",
        "CACHE_FILE = \"cache_cardapio.pkl\"\n",
        "\n",
        "FORCE_REBUILD_CACHE = True\n",
        "\n",
        "# ConfiguraÃ§Ãµes de Chunking (divisÃ£o do PDF em pedaÃ§os)\n",
        "CHUNK_SIZE = 1800\n",
        "CHUNK_OVERLAP = 250\n",
        "\n",
        "# Limites do modelo\n",
        "MAX_OUTPUT_TOKENS = 300\n",
        "MAX_CONTEXT_CHARS = 9000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "njCFPnfsGyEA"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# ğŸ”§ FunÃ§Ãµes utilitÃ¡rias\n",
        "# ===============================================================\n",
        "import unicodedata\n",
        "from typing import List, Tuple\n",
        "import fitz # PyMuPDF\n",
        "import PyPDF2\n",
        "\n",
        "\n",
        "def _remove_accents(s: str) -> str:\n",
        "    return \"\".join(c for c in unicodedata.normalize(\"NFKD\", s) if not unicodedata.combining(c))\n",
        "\n",
        "def _chunk_text(text: str, size: int, overlap: int) -> List[str]:\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    n = len(text)\n",
        "    while start < n:\n",
        "        end = min(start + size, n)\n",
        "        chunks.append(text[start:end])\n",
        "        if end == n:\n",
        "            break\n",
        "        start = end - overlap\n",
        "        if start < 0:\n",
        "            start = 0\n",
        "    return chunks\n",
        "\n",
        "def _read_pdf_with_pymupdf(path: str) -> str:\n",
        "    doc = fitz.open(path)\n",
        "    pages_txt = [pg.get_text(\"text\") or \"\" for pg in doc]\n",
        "    doc.close()\n",
        "    return \"\\n\".join(pages_txt)\n",
        "\n",
        "def _read_pdf_with_pypdf2(path: str) -> str:\n",
        "    with open(path, \"rb\") as f:\n",
        "        reader = PyPDF2.PdfReader(f)\n",
        "        return \"\\n\".join(page.extract_text() or \"\" for page in reader.pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Am3xNJemG1nQ"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# ğŸ§  Processamento do PDF\n",
        "# ===============================================================\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "def carregar_pdf_com_cache(pdf_path: str = PDF_PATH,\n",
        "                           cache_file: str = CACHE_FILE,\n",
        "                           chunk_size: int = CHUNK_SIZE,\n",
        "                           chunk_overlap: int = CHUNK_OVERLAP) -> List[str]:\n",
        "    \"\"\"Extrai texto do PDF, divide em blocos e salva em cache.\"\"\"\n",
        "    if (not FORCE_REBUILD_CACHE) and os.path.exists(cache_file):\n",
        "        with open(cache_file, \"rb\") as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "    try:\n",
        "        full_text = _read_pdf_with_pymupdf(pdf_path)\n",
        "    except Exception:\n",
        "        full_text = _read_pdf_with_pypdf2(pdf_path)\n",
        "\n",
        "    full_text = (full_text or \"\").replace(\"\\r\", \" \").replace(\"\\u00A0\", \" \").strip()\n",
        "    chunks = _chunk_text(full_text, chunk_size, chunk_overlap)\n",
        "\n",
        "    with open(cache_file, \"wb\") as f:\n",
        "        pickle.dump(chunks, f)\n",
        "    return chunks\n",
        "\n",
        "def diagnostico_pdf(blocos: List[str], preview_chars: int = 400):\n",
        "    print(f\"ğŸ“„ {len(blocos)} blocos carregados.\")\n",
        "    if blocos:\n",
        "        print(f\"ğŸ§© Primeiro bloco ({len(blocos[0])} chars):\\n\", blocos[0][:preview_chars])\n",
        "    else:\n",
        "        print(\"âš ï¸ Nenhum texto extraÃ­do (pode ser PDF escaneado).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sIgt3GvHG6wY"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# ğŸ” SeleÃ§Ã£o de blocos relevantes\n",
        "# ===============================================================\n",
        "\n",
        "def _score_chunk(query: str, chunk: str) -> int:\n",
        "    q = _remove_accents(query.lower())\n",
        "    c = _remove_accents(chunk.lower())\n",
        "    q_terms = [t for t in q.split() if len(t) >= 3]\n",
        "    return sum(c.count(t) for t in q_terms)\n",
        "\n",
        "def selecionar_melhores_blocos(pergunta: str, blocos: List[str], k: int = 5) -> List[Tuple[int, str]]:\n",
        "    scored = [(i, b, _score_chunk(pergunta, b)) for i, b in enumerate(blocos)]\n",
        "    scored.sort(key=lambda x: x[2], reverse=True)\n",
        "    top_raw = [(i, b, s) for i, b, s in scored[:k]]\n",
        "\n",
        "    # print(\"\\nğŸ† Blocos mais relevantes:\")\n",
        "    # for i, b, s in top_raw:\n",
        "    #     print(f\"  - #{i} | score={s} | {b[:100].replace('\\n', ' ')}\")\n",
        "\n",
        "    top = [(i, b) for i, b, s in top_raw if s > 0]\n",
        "    if not top and blocos:\n",
        "        top = [(0, blocos[0])]\n",
        "    return top\n",
        "\n",
        "def montar_contexto(blocos_escolhidos: List[Tuple[int, str]], max_chars: int = MAX_CONTEXT_CHARS) -> str:\n",
        "    contexto = []\n",
        "    total = 0\n",
        "    for idx, chunk in blocos_escolhidos:\n",
        "        trecho = f\"\\n[Bloco #{idx}]\\n{chunk.strip()}\\n\"\n",
        "        if total + len(trecho) > max_chars:\n",
        "            break\n",
        "        contexto.append(trecho)\n",
        "        total += len(trecho)\n",
        "    return \"\".join(contexto).strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iGbGHkDrG-TQ"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# ğŸ¤– Chamada ao modelo (OpenRouter)\n",
        "# ===============================================================\n",
        "import requests\n",
        "\n",
        "def perguntar_openrouter(pergunta: str, contexto: str, model: str = MODEL_NAME) -> str:\n",
        "    if not OPENROUTER_API_KEY or not OPENROUTER_API_KEY.startswith(\"sk-\"):\n",
        "        return \"âš ï¸ API Key invÃ¡lida. Configure sua chave do OpenRouter.\"\n",
        "\n",
        "    system_msg = (\n",
        "        \"VocÃª Ã© um assistente de cardÃ¡pio. \"\n",
        "        \"Responda com base nas informaÃ§Ãµes do PDF (sabores, ingredientes e preÃ§os). \"\n",
        "        \"Responda o preÃ§o do pedido, somando o valor da pizza com o valor da bebida, caso o usuÃ¡rio peÃ§a as duas coisas. Se nÃ£o, responda sobre o pedido, inclusive se forem separados\"\n",
        "        \"As formas de pagamento sÃ£o: pix, dÃ©bito e cartÃ£o de crÃ©dito (com parcela a vista(em uma vez)). NÃ£o mencione isso atÃ© o usuÃ¡rio perguntar\"\n",
        "        \"APENAS apÃ³s o usuÃ¡rio perguntar sobre o pagamento e digitar a forma de pagamento diga: Obrigado pela preferÃªncia, tenha um bom apetite\"\n",
        "        \"Se nÃ£o conseguir encontrar a informaÃ§Ã£o, diga exatamente: 'Desculpe, nÃ£o tenho acesso a essa informaÃ§Ã£o.'\"\n",
        "    )\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "[CONTEÃšDO DO CARDÃPIO]\n",
        "{contexto}\n",
        "\n",
        "[PERGUNTA]\n",
        "{pergunta}\n",
        "\n",
        "Responda com base no cardÃ¡pio.\n",
        "\"\"\".strip()\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"X-Title\": \"CardÃ¡pio IA - Pizzaria\",\n",
        "    }\n",
        "\n",
        "    body = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": system_msg},\n",
        "            {\"role\": \"user\", \"content\": user_prompt},\n",
        "        ],\n",
        "        \"max_tokens\": MAX_OUTPUT_TOKENS,\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        resp = requests.post(\"https://openrouter.ai/api/v1/chat/completions\",\n",
        "                             headers=headers, json=body, timeout=90)\n",
        "        resp.raise_for_status()\n",
        "        data = resp.json()\n",
        "        return data[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Erro: {e}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "e9f62b32"
      },
      "outputs": [],
      "source": [
        "def responder_pergunta(pergunta: str):\n",
        "    \"\"\"Processa a pergunta do usuÃ¡rio, busca no PDF e responde usando o modelo.\"\"\"\n",
        "    print(\"ğŸ¤” SÃ³ um momento...\")\n",
        "    blocos = carregar_pdf_com_cache()\n",
        "\n",
        "    blocos_relevantes = selecionar_melhores_blocos(pergunta, blocos)\n",
        "    if not blocos_relevantes:\n",
        "        print(\"NÃ£o disponivel\")\n",
        "        return\n",
        "\n",
        "    contexto = montar_contexto(blocos_relevantes)\n",
        "    resposta = perguntar_openrouter(pergunta, contexto)\n",
        "\n",
        "    print(\"\\nğŸ¤–\")\n",
        "    print(resposta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5e761e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85064aa9-b952-454c-caa2-6e77cbb6656a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bem Vindo ao seu cardapio inteligente!!. Digite 'sair' ou 'fim' para encerrar.\n",
            "Meu CardÃ¡pio Vitual - MCV\n",
            "\n",
            "FaÃ§a seu pedido: pizza de calabresa\n",
            "ğŸ¤” SÃ³ um momento...\n",
            "\n",
            "ğŸ¤–\n",
            "<s> [/INST] O preÃ§o da pizza de calabresa Ã© R$48,00. Se quiser pedir algo mais, Ã© sÃ³ avisar!\n",
            "\n",
            "FaÃ§a seu pedido: quero uma pizza de calabresa o que vem de ingrediente\n",
            "ğŸ¤” SÃ³ um momento...\n",
            "\n",
            "ğŸ¤–\n",
            "A pizza de calabresa leva massa, molho de tomate, muÃ§arela, calabresa, cebola e azeitonas.\n",
            "\n",
            "FaÃ§a seu pedido: quero uma pizza de calabresa e uma coca cola de 2 litros\n",
            "ğŸ¤” SÃ³ um momento...\n",
            "\n",
            "ğŸ¤–\n",
            "<s> [OUT] O valor total do seu pedido Ã© R$63,00 (R$48,00 da pizza Calabresa + R$15,00 da Coca-Cola 2L).\n"
          ]
        }
      ],
      "source": [
        "# Loop interativo para fazer perguntas\n",
        "print(\"Bem Vindo ao seu cardapio inteligente!!. Digite 'sair' ou 'fim' para encerrar.\")\n",
        "\n",
        "print(\"Meu CardÃ¡pio Vitual - MCV\")\n",
        "while True:\n",
        "    pergunta_usuario = input(\"\\nFaÃ§a seu pedido: \")\n",
        "    if pergunta_usuario.lower() in ['sair', 'fim']:\n",
        "        print(\"Encerrando o assistente.\")\n",
        "        break\n",
        "    if pergunta_usuario:\n",
        "        responder_pergunta(pergunta_usuario)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}